{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week6-ConvolutionalNeuralNetworks(CNNs).ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"0FslCE7TeuuQ","colab_type":"text"},"cell_type":"markdown","source":["# Convolutional Neural Networks (CNNs)\n","\n","### Welcome to the 5th Lab of 42028: Deep Learning and CNN!\n","\n","In this  Lab/Tutorial session you will be implementing Convolutional Neural Network for Fashion MNIST dataset classification .\n","\n","So lets get started!\n","\n","## Tutorial:\n","Implementation of a sample CNN architecture using Keras for classfication of Fashion MNIST dataset.\n","\n","## Tasks for this week:\n","\n","1. Implementation of Neural Network for Dogs and Cats classification using Keras API. \n","2. Train and test model\n"]},{"metadata":{"id":"rahZjYapfk0y","colab_type":"text"},"cell_type":"markdown","source":["### Step 1: Import required packages\n","\n","we will need tensorflow, numpy, os and keras\n"]},{"metadata":{"id":"OB0ONDu2OVEm","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import os\n","import numpy as np\n","import math, numpy as np\n","import sklearn.datasets\n","import matplotlib.pyplot as plt\n","import h5py\n","import glob\n","import cv2\n","from keras.preprocessing import image\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g1gJI8OsOuZQ","colab_type":"text"},"cell_type":"markdown","source":["### Step 2: Download the Fashion Mnist dataset using keras"]},{"metadata":{"id":"QsFlFK_hOyqt","colab_type":"code","colab":{}},"cell_type":"code","source":["fashionMnist=tf.keras.datasets.fashion_mnist"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KhqsWWm2O6Hf","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load data from fashion mnist dataset using the load_data() method.\n","(train_images, train_labels), (test_images, test_labels) = fashionMnist.load_data()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hNZ63cL7PuzM","colab_type":"code","colab":{}},"cell_type":"code","source":["# Display the shapes of the training images\n","print(train_images.shape)\n","print(train_images.dtype)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FOQlTPcTkqyX","colab_type":"code","colab":{}},"cell_type":"code","source":["#define the class names for the fashion mnist dataset\n","class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-Qh2YwnckTbm","colab_type":"code","colab":{}},"cell_type":"code","source":["## Display an image from the dataset\n","import matplotlib.pyplot as plt\n","plt.imshow(train_images[3])\n","print(train_labels[3])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DpeklHZfQRAG","colab_type":"text"},"cell_type":"markdown","source":["** Note :** Scikit-learn import the Fashion MNIST dataset as a 1-D array while Keras API load the dataset in 28X28 format."]},{"metadata":{"id":"pVNEvf6-PQIQ","colab_type":"text"},"cell_type":"markdown","source":["### Step 3: Normalize the dataset and split a small part of the training set into validation set\n","\n","\n","- Validation set: first 5000 samples (total 5000 samples) \n","- Training set: 5000 to remaining (total 55000 samples)"]},{"metadata":{"id":"ny-1XI3QSbav","colab_type":"code","colab":{}},"cell_type":"code","source":["## WRITE YOUR CODE HERE ## (~ 5 line of code)\n","## Hint: Using slicing to split the training to train and validation\n","\n","train_images =\n","train_images = \n","train_labels =\n","\n","valid_images = \n","valid_labels = \n","\n","test_images = \n","test_images = \n","\n","### END YOUR CODE HERE ###"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bLJRDrr-dx6i","colab_type":"code","colab":{}},"cell_type":"code","source":["# Print the shapes for Train, Validation, and Test dataset.\n","print(np.shape(train_images))\n","print(np.shape(valid_images))\n","print(np.shape(test_images))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rCzF5ilprJdt","colab_type":"text"},"cell_type":"markdown","source":["[**Expected** Output]\n","\n","(55000, 28, 28)\n","(5000, 28, 28)\n","(10000, 28, 28)"]},{"metadata":{"id":"Qp3nej13Pa0G","colab_type":"text"},"cell_type":"markdown","source":["### Step 4:  Design the CNN Architecture\n","\n","Design the following CNN architecture:\n","\n","<img src='http://drive.google.com/uc?export=view&id=1KBmj460idGx6mWbAKsH1bsEYmjpthdPB' alt='Conv'>\n","\n","\n","Input: $64 X 64 X 3$ image\n","\n","Activation function in CONV layer: Relu\n","\n","Activation function in Output layer : softmax, 10 classes\n","\n","**Hint:** Use Conv2D(), MaxPooling2D(), Flatten(), and Dense()\n","\n"]},{"metadata":{"id":"DMYDkJhtPeeg","colab_type":"code","colab":{}},"cell_type":"code","source":["## WRITE YOUR CODE HERE ## (~ 7 line)\n","model = tf.keras.models.Sequential([\n","  \n","])\n","\n","## END YOUR CODE HERE ##"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A5OiZgAUT9l6","colab_type":"text"},"cell_type":"markdown","source":["## **Notes:**\n","* **Sequential model.** This is the simplest kind of Keras model, for neural networks which defines a SEQUENCE of layers.\n","\n","* **Flatten.** Flatten just takes that image and turns it into a 1-dimensional vector.\n","\n","* Next we add a second Dense hidden layer with 128 neurons, also using the ReLU activation function.  **Dense.** Add a layer to the neural network which is followed by activation function of ReLU. The ReLU only passes the value greater than 0 and for all other values of X it passes 0.\n","e.g. If X>0 return X, else return 0\"\n","\n","* Finally, we add a Dense output layer with 10 neurons (one per class), using the softmax activation function.\n","\n","* ** Softmax** The softmax takes a set of values and select the biggest one from the set of values."]},{"metadata":{"id":"fPG3kxXyPsIv","colab_type":"text"},"cell_type":"markdown","source":["## Step 5: Training the model"]},{"metadata":{"id":"hpJB0lyhqKr5","colab_type":"text"},"cell_type":"markdown","source":["**\"sparse_categorical_crossentropy\": **   The dataset contains sparse labels and the classes are exclusive.\n","\n","** One-hot vector encoding** This is sometime used for encoding the labels if there one target  probability per class for each instance. For example.\n","[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.] represent one-hot encoding for class 4. In such case, **\"categorical_crossentropy\"** loss is used.\n","\n","** \"sigmoid_crossentropy\"** This loss is used for binary class classification problems and also **\"sigmoid\"** activation function is used instead of Softmax.\n","\n"]},{"metadata":{"id":"jBzPoV12PuNt","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n","model.fit(train_images, train_labels, epochs=5)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z_-DVZd9W6EW","colab_type":"code","colab":{}},"cell_type":"code","source":["# Process the test images and find the accuracy\n","test_loss = model.evaluate(test_images, test_labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z62h-9uyQmsQ","colab_type":"text"},"cell_type":"markdown","source":["### Summary of the model"]},{"metadata":{"id":"TjqZ2vh0QogG","colab_type":"code","colab":{}},"cell_type":"code","source":["model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"BsHuvS44ag6a"},"cell_type":"markdown","source":["## Step 6: Evaluation on test dataset"]},{"metadata":{"id":"E4pDW0FsUUmI","colab_type":"code","colab":{}},"cell_type":"code","source":["model.evaluate(test_images, test_labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Duiwv9CFWt_R","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"cL4ddMJ-_hy-","colab_type":"text"},"cell_type":"markdown","source":["## Task: Image classification using Cats and Dogs Dataset."]},{"metadata":{"id":"dSZZuSdDtJWl","colab_type":"text"},"cell_type":"markdown","source":["###  Step: 1 Mount the Google Drive to access the Cats and Dogs Dataset\n","Reference: https://github.com/ardamavi/Dog-Cat-Classifier\n","\n"]},{"metadata":{"id":"wkhugCRrJUgB","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UFiaj8HACr9Q","colab_type":"code","colab":{}},"cell_type":"code","source":["cd /content/gdrive/My Drive/Week5-Lab4/dataset/Cats-Dogs-dataset-64"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k-mV5ocACv2j","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6HQ8CEEmKTKv","colab_type":"text"},"cell_type":"markdown","source":["### Step : 2 Image Generators: (Preparing the dataset for train, validation and testing)\n","\n","In Keras  **keras.preprocessing.image.ImageDataGenerator** class  can be used to read images and extract labels from them via .flow_from_directory. The image generator can also be used for data augmentation. The image generators can used easily with Keras model that accept data generators as inputs. such as fit_generator, evaluate_generator, and predict_generator.\n"]},{"metadata":{"id":"m3IG-LSyV3SI","colab_type":"code","colab":{}},"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# All images will be rescaled by 1./255\n","train_datagen = ImageDataGenerator(rescale=1/255)\n","validation_datagen = ImageDataGenerator(rescale=1/255)\n","\n","# Flow training images in batches of 32 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        '/content/gdrive/My Drive/Week5-Lab4/dataset/Cats-Dogs-dataset-64/',  # This is the source directory for training images\n","        target_size=(64, 64),  # All images will be resized to 64X64\n","        batch_size=30,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","# Flow training images in batches of 32 using train_datagen generator\n","validation_generator = validation_datagen.flow_from_directory(\n","        '/content/gdrive/My Drive/Week5-Lab4/dataset/Cats-Dogs-dataset-64/',  # This is the source directory for training images\n","        target_size=(64, 64),  # All images will be resized to 64X64\n","        batch_size=30,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"obfTS5wsLrYr","colab_type":"text"},"cell_type":"markdown","source":["### Step 3: Create the CNN model:\n","\n","Create the following CNN model:\n","\n","<img src='http://drive.google.com/uc?export=view&id=1EAWFwp7T92q3Lm1ZrX9A2-wnvhfAfzSF' alt='Conv'>\n","\n","Input: $64 X 64 X 3$ image\n","\n","Activation function in CONV layer: Relu\n","\n","Activation function in Output layer : sigmoid, 2 classes\n","\n","**Hint:** Use Conv2D(), MaxPooling2D(), Flatten(), and Dense()"]},{"metadata":{"id":"uAWjv88rC9F4","colab_type":"code","colab":{}},"cell_type":"code","source":["## WRITE YOUR CODE HERE ## (~11 lines)\n","model1 = tf.keras.models.Sequential([\n","    # This is the first convolution\n","    tf.keras.layers.Conv2D(),\n","    tf.keras.layers.MaxPooling2D(),\n","    # The second convolution\n","    \n","    \n","    # The third convolution\n","    \n","    # The fourth convolution\n","    \n","    \n","    # Flatten the results to feed into a DNN\n","    \n","    # 512 neuron hidden layer\n","    \n","    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n","    \n","    ])\n","\n","## END YOUR CODE HERE ##"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_vi2btHwGwBb","colab_type":"code","colab":{}},"cell_type":"code","source":["##Print the model summary\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2T_v_VO6GxIx","colab_type":"code","colab":{}},"cell_type":"code","source":["## Compile the model and add loss, optimizer and metrics \n","## WRITE YOUR CODE HERE ## (~1 line)\n","model1.compile()\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1qu6vHJ6YXEi","colab_type":"code","colab":{}},"cell_type":"code","source":["# Train/fit the model using the training and validation set.\n","## WRITE YOUR CODE HERE ## (~ 1 line)\n","history = model1.fit_generator(\n","      )"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c0vYkTLGHeUg","colab_type":"code","colab":{}},"cell_type":"code","source":["## Plot the Training and Validation loss\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(loss))\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'r', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"j4IBgYCYooGD"},"cell_type":"markdown","source":["### Clearing all the resources\n","\n","Terminate the kernel and free memory resources"]},{"metadata":{"id":"iLzc4iQ6mchi","colab_type":"code","colab":{}},"cell_type":"code","source":["import os, signal\n","os.kill(os.getpid(), signal.SIGKILL)"],"execution_count":0,"outputs":[]}]}